{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL5y5fY9Jy_x"
      },
      "source": [
        "# Binary Classification | Binær klassifikation\n",
        "\n",
        "Indtil videre har du kun oprettet regressionsmodeller. Det vil sige, at du har oprettet modeller, der producerede flydende punktprediktioner, såsom \"huse i dette område koster N tusind dollars.\" I denne vejledning vil du oprette og evaluere en binær [klassifikationsmodel](https://developers.google.com/machine-learning/glossary/#classification_model). Det vil sige, at du vil oprette en model, der besvarer en binær spørgsmål. I dette øvelse vil spørgsmålet være, \"Er huse i dette område over en bestemt pris?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuw8rRl9lNuL"
      },
      "source": [
        "## Læringsmål\n",
        "\n",
        "Efter at have gennemført denne vejledning, vil du kunne:\n",
        "\n",
        "  * Konvertere et regressionsspørgsmål til et klassifikationsspørgsmål.\n",
        "  * Ændre klassifikationsgrænsen og bestemme, hvordan denne ændring påvirker modellen.\n",
        "  * Experimentere med forskellige klassifikationsmetrikker for at bestemme modellens effektivitet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44OdC-OglN9D"
      },
      "source": [
        "## Datasættet\n",
        "\n",
        "Vores datasæt er Californien Housing Data. Som kan findes på: https://developers.google.com/machine-learning/crash-course/california-housing-data-description\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iuw6-JOGf7I"
      },
      "source": [
        "## Indlæsning af nødvendige moduler\n",
        "\n",
        "Følgende kode importerer de nødvendige moduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9n9_cTveKmse"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# The following lines adjust the granularity of reporting.\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "# tf.keras.backend.set_floatx('float32')\n",
        "\n",
        "print(\"Ran the import statements.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_TaJhU4KcuY"
      },
      "source": [
        "## Hent datasættet fra internettet\n",
        "\n",
        "Følgende kode celler loader de separate .csv filer og opretter følgende to pandas DataFrames:\n",
        "\n",
        "* `train_df`, som indeholder træningssættet\n",
        "* `test_df`, som indeholder test sættet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZlvdpyYKx7V"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
        "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")\n",
        "train_df = train_df.reindex(np.random.permutation(train_df.index)) # shuffle the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G6y-XcEmk6r"
      },
      "source": [
        "## Normalisering af datasættet\n",
        "\n",
        "Når du opretter en model med flere funktioner, skal værdierne for hver funktion dække omtrent samme område. For eksempel, hvis et område har en værdi på 500 til 100.000 og et andet område har en værdi på 2 til 12, så vil modellen være svær at træne. Derfor skal du\n",
        "[normalisere](https://developers.google.com/machine-learning/glossary/#normalization) funktioner i en model med flere funktioner.\n",
        "\n",
        "\n",
        "Følgende kode normaliserer datasættene ved at konvertere hver rå værdi (inklusive labelen) til sin Z-score. En **Z-score** er antallet af standardafvigelser fra middelværdien for en bestemt rå værdi. For eksempel, overvej en funktion, der har følgende karakteristika:\n",
        "\n",
        "\n",
        "  * Middelværdien er 60.\n",
        "  * Standardafvigelsen er 10.\n",
        "\n",
        "\n",
        "Den rå værdi 75 ville have en Z-score på +1.5:\n",
        "\n",
        "\n",
        "```\n",
        "  Z-score = (75 - 60) / 10 = +1.5\n",
        "```\n",
        "\n",
        "Den rå værdi 38 ville have en Z-score på -2.2:\n",
        "\n",
        "```\n",
        "  Z-score = (38 - 60) / 10 = -2.2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7nuAHoZIgVI"
      },
      "outputs": [],
      "source": [
        "# Calculate the Z-scores of each column in the training set and\n",
        "# write those Z-scores into a new pandas DataFrame named train_df_norm.\n",
        "train_df_mean = train_df.mean()\n",
        "train_df_std = train_df.std()\n",
        "train_df_norm = (train_df - train_df_mean)/train_df_std\n",
        "\n",
        "# Examine some of the values of the normalized training set. Notice that most\n",
        "# Z-scores fall between -2 and +2.\n",
        "train_df_norm.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoW-59jVFF2I"
      },
      "outputs": [],
      "source": [
        "# Calculate the Z-scores of each column in the test set and\n",
        "# write those Z-scores into a new pandas DataFrame named test_df_norm.\n",
        "test_df_norm = (test_df - train_df_mean) / train_df_std\n",
        "\n",
        "# Note that we transform the test data with the values calculated from the training set,\n",
        "# as you should always transform your datasets with exactly the same values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-swmXtWnZGis"
      },
      "source": [
        "## Opgave 1: Opret en binær label\n",
        "\n",
        "I klassifikationsproblemer skal labelen for hver eksempel være enten 0 eller 1. Desværre indeholder den naturlige label i Californien Housing Datasættet, `median_house_value`, floating-point værdier som 80.100 eller 85.700 i stedet for 0'er og 1'er, mens den normaliserede version af `median_house_values` indeholder floating-point værdier primært mellem -3 og +3.\n",
        "\n",
        "\n",
        "Din opgave er at oprette en ny kolonne med navnet `median_house_value_is_high` i både træningssættet og testsættet. Hvis `median_house_value` er højere end en bestemt vilkårlig værdi (defineret af `threshold`), så sæt `median_house_value_is_high` til 1. Ellers sæt `median_house_value_is_high` til 0.\n",
        "\n",
        "\n",
        "**Hint:** Cellerne i `median_house_value_is_high` kolonnen skal hver isætte `1` og `0`, ikke `True` og `False`. For at konvertere `True` og `False` til `1` og `0`, kalder du pandas DataFrame funktionen `astype(float)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4kWfWA8bhKW"
      },
      "outputs": [],
      "source": [
        "threshold = 265000 # This is the 75th percentile for median house values.\n",
        "train_df_norm[\"median_house_value_is_high\"] = ? Your code here\n",
        "test_df_norm[\"median_house_value_is_high\"] = ? Your code here\n",
        "\n",
        "# Print out a few example cells from the beginning and\n",
        "# middle of the training set, just to make sure that\n",
        "# your code created only 0s and 1s in the newly created\n",
        "# median_house_value_is_high column\n",
        "train_df_norm[\"median_house_value_is_high\"].head(8000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kir8UTUXSV8"
      },
      "source": [
        "## Reprensentere funktioner som inputlag\n",
        "\n",
        "Denne kode celle specificerer funktionerne, `median_income` og ` total_rooms`, som du vil træne modellen på. Disse [Input](https://www.tensorflow.org/api_docs/python/tf/keras/Input) objekter er instansieret som Keras tensors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tmmZIDw4JEC"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "# Features used to train the model on.\n",
        "  'median_income': tf.keras.Input(shape=(1,)),\n",
        "  'total_rooms': tf.keras.Input(shape=(1,))\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3014ezH3C7jT"
      },
      "source": [
        "## Definere funktioner, der bygger og træner en model\n",
        "\n",
        "Denne kode celle definerer to funktioner: \n",
        "\n",
        "  * `create_model(inputs, learning_rate, METRICS)`, som definerer modellens\n",
        "    topografi.\n",
        "\n",
        "  * `train_model(model, dataset, epochs, label_name, batch_size, shuffle)`, bruger input funktioner og labels til at træne modellen.\n",
        "\n",
        "I dette øvelseseksempel bruger vi [sigmoid](https://developers.google.com/machine-learning/glossary#sigmoid-function) som aktiveringsfunktion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pedD5GhlDC-y"
      },
      "outputs": [],
      "source": [
        "def create_model(my_inputs, my_learning_rate, METRICS):\n",
        "  # Use a Concatenate layer to concatenate the input layers into a single tensor.\n",
        "  # as input for the Dense layer. Ex: [input_1[0][0], input_2[0][0]]\n",
        "  concatenated_inputs = tf.keras.layers.Concatenate()(my_inputs.values())\n",
        "  dense = layers.Dense(units=1, name='dense_layer', activation=tf.sigmoid)\n",
        "  dense_output = dense(concatenated_inputs)\n",
        "  \"\"\"Create and compile a simple classification model.\"\"\"\n",
        "  my_outputs = {\n",
        "    'dense': dense_output,\n",
        "  }\n",
        "  model = tf.keras.Model(inputs=my_inputs, outputs=my_outputs)\n",
        "\n",
        "  # Call the compile method to construct the layers into a model that\n",
        "  # TensorFlow can execute.  Notice that we're using a different loss\n",
        "  # function for classification than for regression.\n",
        "  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=METRICS)\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, label_name,\n",
        "                batch_size=None, shuffle=True):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  # The x parameter of tf.keras.Model.fit can be a list of arrays, where\n",
        "  # each array contains the data for one feature.  Here, we're passing\n",
        "  # every column in the dataset. Note that the feature_layer will filter\n",
        "  # away most of those columns, leaving only the desired columns and their\n",
        "  # representations as features.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=shuffle)\n",
        "\n",
        "  # The list of epochs is stored separately from the rest of history.\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # Isolate the classification metric for each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist\n",
        "\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak_TMAzGOIFq"
      },
      "source": [
        "## Definere en plotting funktion\n",
        "\n",
        "Denne [matplotlib](https://developers.google.com/machine-learning/glossary/#matplotlib) funktion plotter en eller flere kurver, der viser, hvordan forskellige klassifikationsmålinger ændrer sig med hver epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QF0BFRXTOeR3"
      },
      "outputs": [],
      "source": [
        "def plot_curve(epochs, hist, list_of_metrics):\n",
        "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"\n",
        "  # list_of_metrics should be one of the names shown in:\n",
        "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Value\")\n",
        "\n",
        "  for m in list_of_metrics:\n",
        "    x = hist[m]\n",
        "    plt.plot(epochs[1:], x[1:], label=m)\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "print(\"Defined the plot_curve function.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-IXYVfvM4gD"
      },
      "source": [
        "## Kald funktionerne til at oprette og træne modellen, og derefter plotte resultaterne.\n",
        "\n",
        "Denne kode celle specificerer hyperparametrene, og derefter kalder funktionerne til at oprette og træne modellen, og derefter plotte resultaterne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "nj3v5EKQFY8s"
      },
      "outputs": [],
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "batch_size = 100\n",
        "label_name = \"median_house_value_is_high\"\n",
        "classification_threshold = 0.35\n",
        "\n",
        "# Establish the metrics the model will measure.\n",
        "METRICS = [\n",
        "           tf.keras.metrics.BinaryAccuracy(name='accuracy',\n",
        "                                           threshold=classification_threshold),\n",
        "          ]\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(inputs, learning_rate, METRICS)\n",
        "\n",
        "# To view a PNG of this model's layers, uncomment the call to\n",
        "# `tf.keras.utils.plot_model` below. After running this code cell, click\n",
        "# the file folder on the left, then the `my_classification_model.png` file.\n",
        "# tf.keras.utils.plot_model(my_model, \"my_classification_model.png\")\n",
        "\n",
        "# Train the model on the training set.\n",
        "epochs, hist = train_model(my_model, train_df_norm, epochs,\n",
        "                           label_name, batch_size)\n",
        "\n",
        "# Plot a graph of the metric(s) vs. epochs.\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF64TpqkbOpn"
      },
      "source": [
        "Accuracy skal gradvist blive bedre under træningen (indtil det ikke kan forbedres yderligere).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xNqWWos_zyk"
      },
      "source": [
        "## Evaluer modellen mod test sættet\n",
        "\n",
        "Efter at have trænet modellen, fik du en vis præcision mod *træningssættet*. Kald følgende kode celle for at bestemme din modelens præcision mod *test sættet*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJorkMlDmtHf"
      },
      "outputs": [],
      "source": [
        "features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
        "label = np.array(features.pop(label_name))\n",
        "\n",
        "my_model.evaluate(x = features, y = label, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7cHkFXalXV5"
      },
      "source": [
        "## Opgave 2: Hvor præcis er din model?\n",
        "\n",
        "Er din model værdifuld? Giv dit svar herunder:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8crSCCVf6gm"
      },
      "source": [
        "## Opgave 3: Tilføj precision og recall som målinger\n",
        "\n",
        "At bruge accuracy, isoleret set, kan være en dårlig måde at vurdere en klassifikationsmodel på. Modificer koden i følgende kode celle for at gøre modellen til at måle ikke kun accuracy, men også precision og recall. Vi har tilføjet accuracy og precision; din opgave er at tilføje recall. Se [TensorFlow Reference](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall) for detaljer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-k1MD2XArmO"
      },
      "outputs": [],
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "batch_size = 100\n",
        "classification_threshold = 0.35\n",
        "label_name = \"median_house_value_is_high\"\n",
        "\n",
        "# Modify the following definition of METRICS to generate\n",
        "# not only accuracy and precision, but also recall:\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy',\n",
        "                                      threshold=classification_threshold),\n",
        "      tf.keras.metrics.Precision(thresholds=classification_threshold,\n",
        "                                 name='precision'\n",
        "                                 ),\n",
        "      ?  # write code here\n",
        "]\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(inputs, learning_rate, METRICS)\n",
        "\n",
        "# Train the model on the training set.\n",
        "epochs, hist = train_model(my_model, train_df_norm, epochs,\n",
        "                           label_name, batch_size)\n",
        "\n",
        "# Plot metrics vs. epochs\n",
        "list_of_metrics_to_plot = ['accuracy', 'precision', 'recall']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAsB85iKSXLe"
      },
      "source": [
        "## Opgave 4: Eksperimenter med klassifikationsgrænsen (Hvis du har ekstra tid)\n",
        "\n",
        "Eksperimenter med forskellige værdier for `classification_threshold` i koden i cellen \"Invoke the creating, training, and plotting functions.\"  Hvilken værdi for `classification_threshold` producerer den højeste præcision?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FLPDYI7Sphnj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBGRS0Ndduus"
      },
      "source": [
        "## Opgave 5: Opsummere modellens ydeevne (Hvis du har ekstra tid)\n",
        "\n",
        "Hvis du har ekstra tid, tilføj en anden måling, der forsøger at opsummere modellens samlede ydeevne.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vwNE6syoFvWe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Binary Classification.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
